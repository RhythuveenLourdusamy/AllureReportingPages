Evaluating test cases...
**************************************************
Contextual Recall Verbose Logs
**************************************************

Verdicts:
[
    {
        "verdict": "yes",
        "reason": "The structure 'condition': 'AND' and 'matchGroups' are present in the 1st node of the retrieval context."
    },
    {
        "verdict": "no",
        "reason": "The 'id' value '1388' does not match the 'id' value '1355' found in the 1st node of the retrieval context."
    },
    {
        "verdict": "yes",
        "reason": "The structure 'type': 'list_membership', 'condition': 'AND', and 'criteria' are present in the 1st node of the retrieval context."
    },
    {
        "verdict": "no",
        "reason": "The 'operation': 'eq' and 'resourceMatchType': 'specificResource' is not found in the 1st node of the retrieval context."
    }
]


Score: 0.5
Reason: The score is 0.50 because the expected output correctly aligns with the structure of the condition and matchGroups (sentence 1), as well as the type, condition, and criteria (sentence 2) from the 1st node in the retrieval context. However, the specific 'id' value '1388' and details such as 'operation' and 'resourceMatchType' do not correspond with the information in the 1st node in the retrieval context.

======================================================================
**************************************************
Answer Relevancy Verbose Logs
**************************************************

Statements:
[
    "condition: AND",
    "matchGroups",
    "condition: AND",
    "matches",
    "type: list_membership",
    "condition: AND",
    "criteria",
    "id: 1355",
    "operation: eq"
]


Verdicts:
[
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    }
]


Score: 1.0
Reason: The score is 1.00 because the output is fully relevant to the input provided.

======================================================================
✨ You're running DeepEval's latest Contextual Recall Metric! (using azure open…
✨ You're running DeepEval's latest Answer Relevancy Metric! (using azure opena…

======================================================================

Metrics Summary

  - ❌ Contextual Recall (score: 0.5, threshold: 0.8, strict: False, evaluation model: azure openai, reason: The score is 0.50 because the expected output correctly aligns with the structure of the condition and matchGroups (sentence 1), as well as the type, condition, and criteria (sentence 2) from the 1st node in the retrieval context. However, the specific 'id' value '1388' and details such as 'operation' and 'resourceMatchType' do not correspond with the information in the 1st node in the retrieval context., error: None)
  - ✅ Answer Relevancy (score: 1.0, threshold: 0.6, strict: False, evaluation model: azure openai, reason: The score is 1.00 because the output is fully relevant to the input provided., error: None)

For test case:

  - input: Get me contacts who are members of the list 'freshservice-FS knowledge mgmt eBook'
  - actual output: {
    "condition": "AND",
    "matchGroups": [
        {
            "condition": "AND",
            "matches": [
                {
                    "type": "list_membership",
                    "condition": "AND",
                    "criteria": {
                        "id": 1355,
                        "operation": "eq"
                    }
                }
            ]
        }
    ]
}
  - expected output: {"condition": "AND", "matchGroups": [{"matches": [{"type": "list_membership", "filters": [], "criteria": {"id": "1388", "operation": "eq", "resourceMatchType": "specificResource"}, "condition": "AND"}], "condition": "AND"}]}
  - context: None
  - retrieval context: ['{\n    "condition": "AND",\n    "matchGroups": [\n        {\n            "condition": "AND",\n            "matches": [\n                {\n                    "type": "list_membership",\n                    "condition": "AND",\n                    "criteria": {\n                        "id": 1355,\n                        "operation": "eq"\n                    }\n                }\n            ]\n        }\n    ]\n}']

======================================================================

Overall Metric Pass Rates

Contextual Recall: 0.00% pass rate
Answer Relevancy: 100.00% pass rate

======================================================================

✅ Tests finished! View results on 
https://app.confident-ai.com/project/clwzxg76s000clc0ch0w2kpcw/unit-tests/cly0wv
dvf075wup7nkmo31pn4/test-cases
