Evaluating test cases...
**************************************************
Contextual Recall Verbose Logs
**************************************************

Verdicts:
[
    {
        "verdict": "yes",
        "reason": "The sentence can be attributed to the 1st node, specifically the criteria object with 'fieldId': '9e1bd83e-c2c5-4277-98aa-04d605e59721' and 'value': '127000008897'."
    },
    {
        "verdict": "yes",
        "reason": "The sentence can be attributed to the 1st node, particularly the criteria object with 'fieldName': 'cf_cf_fservicecustomerstatus'."
    },
    {
        "verdict": "yes",
        "reason": "The sentence can be attributed to the 1st node, specifically the criteria object with 'fieldType': 'dropdown'."
    },
    {
        "verdict": "yes",
        "reason": "The sentence can be attributed to the 1st node, particularly the criteria object with 'columnName': 'cf_dropdown_102'."
    },
    {
        "verdict": "yes",
        "reason": "The sentence can be attributed to the 1st node, specifically the criteria object with 'comparator': 'eq'."
    },
    {
        "verdict": "no",
        "reason": "The 'condition' of the matchGroups differs ('OR' in the expected output vs 'AND' in the retrieval context)."
    }
]


Score: 0.8333333333333334
Reason: The score is 0.83 because most elements in the expected output align well with the 1st node in retrieval context, such as 'fieldId', 'value', 'fieldName', 'fieldType', 'columnName', and 'comparator'. However, the 'condition' of the matchGroups is inconsistent, showing 'OR' instead of 'AND'.

======================================================================
**************************************************
Answer Relevancy Verbose Logs
**************************************************

Statements:
[
    "condition: AND",
    "matchGroups: [object]",
    "condition: AND within match group",
    "matches: [array]",
    "type: contact_field",
    "condition: AND in criteria",
    "criteria: [object]",
    "fieldId: 9e1bd83e-c2c5-4277-98aa-04d605e59721",
    "fieldName: cf_cf_fservicecustomerstatus",
    "columnName: cf_bigint102",
    "fieldType: Select option",
    "comparator: eq",
    "value: 127000008897",
    "secondValue: null",
    "repeatAnnually: false"
]


Verdicts:
[
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "yes",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    },
    {
        "verdict": "idk",
        "reason": null
    }
]


Score: 1.0
Reason: The score is 1.00 because the actual output is perfectly relevant to the input with no irrelevant statements.

======================================================================
✨ You're running DeepEval's latest Contextual Recall Metric! (using azure open…
✨ You're running DeepEval's latest Answer Relevancy Metric! (using azure opena…

======================================================================

Metrics Summary

  - ✅ Contextual Recall (score: 0.8333333333333334, threshold: 0.8, strict: False, evaluation model: azure openai, reason: The score is 0.83 because most elements in the expected output align well with the 1st node in retrieval context, such as 'fieldId', 'value', 'fieldName', 'fieldType', 'columnName', and 'comparator'. However, the 'condition' of the matchGroups is inconsistent, showing 'OR' instead of 'AND'., error: None)
  - ✅ Answer Relevancy (score: 1.0, threshold: 0.6, strict: False, evaluation model: azure openai, reason: The score is 1.00 because the actual output is perfectly relevant to the input with no irrelevant statements., error: None)

For test case:

  - input: Get me contacts whose custom field 'cf_cf_fservicecustomerstatus' is '127000008897'
  - actual output: {
    "condition": "AND",
    "matchGroups": [
        {
            "condition": "AND",
            "matches": [
                {
                    "type": "contact_field",
                    "condition": "AND",
                    "criteria": {
                        "fieldId": "9e1bd83e-c2c5-4277-98aa-04d605e59721",
                        "fieldName": "cf_cf_fservicecustomerstatus",
                        "columnName": "cf_bigint102",
                        "fieldType": "Select option",
                        "comparator": "eq",
                        "value": "127000008897",
                        "secondValue": null,
                        "repeatAnnually": false
                    }
                }
            ]
        }
    ]
}
  - expected output: {"condition": "AND", "matchGroups": [{"matches": [{"type": "contact_field", "filters": [], "criteria": {"value": "127000008897", "fieldId": "9e1bd83e-c2c5-4277-98aa-04d605e59721", "fieldName": "cf_cf_fservicecustomerstatus", "fieldType": "dropdown", "columnName": "cf_dropdown_102", "comparator": "eq"}, "condition": "AND"}], "condition": "OR"}]}
  - context: None
  - retrieval context: ['{\n    "condition": "AND",\n    "matchGroups": [\n        {\n            "condition": "AND",\n            "matches": [\n                {\n                    "type": "contact_field",\n                    "condition": "AND",\n                    "criteria": {\n                        "fieldId": "9e1bd83e-c2c5-4277-98aa-04d605e59721",\n                        "fieldName": "cf_cf_fservicecustomerstatus",\n                        "columnName": "cf_bigint102",\n                        "fieldType": "Select option",\n                        "comparator": "eq",\n                        "value": "127000008897",\n                        "secondValue": null,\n                        "repeatAnnually": false\n                    }\n                }\n            ]\n        }\n    ]\n}']

======================================================================

Overall Metric Pass Rates

Contextual Recall: 100.00% pass rate
Answer Relevancy: 100.00% pass rate

======================================================================

✅ Tests finished! View results on 
https://app.confident-ai.com/project/clwzxg76s000clc0ch0w2kpcw/unit-tests/cly0x9
w7l0785ns2ah7ks52tp/test-cases
